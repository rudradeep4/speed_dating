{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385cc6f8-8370-42b6-b695-371c6c22f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "import pandas as pd\n",
    "# pd.options.mode.copy_on_write = True\n",
    "import numpy as np\n",
    "from scipy.signal import resample as sci_resample\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split, cross_val_score\n",
    "import librosa\n",
    "from mtrf import TRF\n",
    "from mtrf.stats import nested_crossval\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from shapedtw.shapedtw import shape_dtw\n",
    "from shapedtw.shapeDescriptors import SlopeDescriptor\n",
    "import shap\n",
    "from corr_shap import CorrExplainer\n",
    "from pymer4.models import Lm, Lmer\n",
    "\n",
    "sns.set_theme(\n",
    "                style='white', \n",
    "                palette='Dark2',\n",
    "                # rc={\"figure.dpi\": 150}\n",
    "            )\n",
    "# plt.rcParams.update({\n",
    "#     \"figure.facecolor\": (0.0, 0.0, 0.0, 0.0),\n",
    "#     \"axes.facecolor\": (0.0, 0.0, 0.0, 0.0),\n",
    "#     \"legend.facecolor\": (0.0, 0.0, 0.0, 0.0),\n",
    "#     \"savefig.facecolor\": (0.0, 0.0, 0.0, 0.0),\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42199e6-ae73-470c-824a-7752fc394796",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Info:\n",
    "\n",
    "    modality = 'va'\n",
    "    sr = 30\n",
    "    audio_type = 'auditory_nerve'\n",
    "    trf_min_lag = 0\n",
    "    trf_max_lag = 3\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.aus = [\"AU12\",\"AU14\",\"AU15\", \"AU17\",\"AU23\",\"AU24\",\"AU25\",\"AU26\",\"AU28\",\"AU43\",\"Pitch\"]\n",
    "        self.block_map = {'va': 'A->V', 'vv': 'V->V', 'vva': 'AV->V'}\n",
    "        self.regularization = np.logspace(-1, 6, 10)\n",
    "        self.demographics = defaultdict()\n",
    "        self.trfs = defaultdict()\n",
    "        self.important_aus = {\n",
    "            'trf': [],\n",
    "            'dtw': [],\n",
    "            'lm': [],\n",
    "            'glm': []\n",
    "        }\n",
    "\n",
    "\n",
    "    def set_demographics(self, total, gender_count, ages):\n",
    "        self.demographics['N'] = f'{total} (Male={gender_count[\"m\"]+1}, Female={gender_count[\"f\"]})'\n",
    "        self.demographics['Age'] = 'µ={:.2f}, SD={:.2f}'.format(ages.mean(), ages.std())\n",
    "\n",
    "    \n",
    "    def add_trf(self, au, trf):\n",
    "        self.trfs[au] = trf\n",
    "\n",
    "    \n",
    "    def add_important_au(self, category, au, res):\n",
    "        if category == 'trf' or category == 'dtw':\n",
    "            self.important_aus[category].append({au: f\"t({res.df})={res.statistic}, p={res.pvalue:.2f}\"})\n",
    "        else:\n",
    "            self.important_aus[category].append({au: res})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e82e512-9473-4756-82b4-9632e2f84bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = Info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8549d3fd-a9fb-43b8-91f8-25d5c0bfdf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping = {\n",
    "#             'M1': '1_M1_AM', 'M2': '1_M2_AM', 'M3': '1_M3_AM', 'M4': '1_M4_AM',\n",
    "#             'M5': '1_M2_PM', 'M6': '1_M1_PM', 'M7': '1_M3_PM', 'M8': '1_M4_PM',\n",
    "#             'M9': '2_M1_AM', 'M10': '2_M2_AM', 'M11': '2_M3_AM', 'M12': '2_M4_AM',\n",
    "#             'M13': '2_M1_PM', 'M14': '2_M2_PM', 'M15': '2_M3_PM', 'M16': '2_M4_PM',\n",
    "#             'F1': '1_F1_AM', 'F2': '1_F2_AM', 'F3': '1_F3_AM', 'F4': '1_F4_AM',\n",
    "#             'F5': '1_F1_PM', 'F6': '1_F2_PM', 'F7': '1_F3_PM', 'F8': '2_F1_AM',\n",
    "#             'F9': '2_F2_AM', 'F10': '2_F4_AM', 'F11': '2_F3_AM', 'F12': '2_F1_PM',\n",
    "#             'F13': '2_F2_PM', 'F14': '2_F3_PM', 'F15': '2_F4_PM'\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddbba86-c06b-4633-8ac5-ce6128177ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_df = []\n",
    "for dir in (glob.glob(f'./data/responses/*')):\n",
    "    if len(os.listdir(dir)) != 0:\n",
    "        files = glob.glob(dir+'/*.csv')\n",
    "        for i in range(len(files)):\n",
    "            if len(files) == 4:\n",
    "                if i != 0:\n",
    "                    temp_df = pd.read_csv(files[i])\n",
    "                    lst_df.append(temp_df)\n",
    "            else:\n",
    "                temp_df = pd.read_csv(files[i])\n",
    "                lst_df.append(temp_df)\n",
    "                \n",
    "df_responses = pd.concat(lst_df)\n",
    "\n",
    "df_responses['CorrectResp'] = df_responses.Condition.apply(lambda x: 'g' if x=='TRUE' else 'h')\n",
    "df_responses['Accuracy'] = df_responses.CorrectResp==df_responses.Resp\n",
    "df_responses['DisplayedDyad'] = df_responses.AudioPath.str.split('/').str[4]\n",
    "df_responses[['Age','Sex']] = df_responses[['Sex','Age']].where(df_responses.Subject > 5, df_responses[['Age','Sex']].values)\n",
    "df_responses['VideoPath'] = df_responses.VideoPath.str.replace('\\\\', '/')\n",
    "df_responses['Condition'] = df_responses.Condition.apply(lambda x: 'true' if x=='TRUE' else 'fake')\n",
    "df_responses = df_responses.drop('Date', axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ccb81f-5daf-4502-a7f9-0bac189c0286",
   "metadata": {},
   "source": [
    "# Behavioral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6616c6ff-f8fd-4496-a6c0-dda5129775ee",
   "metadata": {},
   "source": [
    "## Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7704195f-2e7e-41c4-b6e4-cd29754d0033",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = df_responses.Subject.nunique()\n",
    "\n",
    "grouped = df_responses.groupby('Subject')\n",
    "sex = grouped.Sex.apply(lambda x: x.iloc[0]).value_counts()\n",
    "age = grouped.Age.apply(lambda x: x.iloc[0])\n",
    "\n",
    "info.set_demographics(N, sex, age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2ea353-6f4c-4818-a6e8-f5eac1d26171",
   "metadata": {},
   "source": [
    "## Response counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a0ffdd-1ca9-4263-8ab3-cbe47885e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
    "plt.tight_layout(h_pad=5, w_pad=10)\n",
    "sns.histplot(x='Resp', data=df_responses, ax=axs[0, 0])\n",
    "axs[0, 0].set_xticks([0, 1], labels=['Yes', 'No'])\n",
    "axs[0, 0].set_xlabel('Response')\n",
    "axs[0, 0].set_title('Was the video you watched a genuine interaction?')\n",
    "\n",
    "sns.histplot(x='LikertResp', data=df_responses, bins=4, discrete=True, ax=axs[0, 1])\n",
    "axs[0, 1].set_xticks([1, 2, 3, 4], labels=['1', '2', '3', '4'])\n",
    "axs[0, 1].set_xlabel('Response')\n",
    "axs[0, 1].set_title('How confident are you in your decision?')\n",
    "\n",
    "sns.histplot(x='Resp', hue='Block', data=df_responses, ax=axs[1, 0], multiple='dodge', element='poly')\n",
    "axs[1, 0].set_xticks([0, 1], labels=['Yes', 'No'])\n",
    "axs[1, 0].set_xlabel('Response')\n",
    "for t, l in zip(axs[1, 0].legend_.texts, ['A -> V', 'V -> V', 'AV -> V']):\n",
    "    t.set_text(l)\n",
    "axs[1, 0].set_title('Was the video you watched a genuine interaction?')\n",
    "sns.move_legend(axs[1, 0], \"upper left\", bbox_to_anchor=(1, 1))\n",
    "\n",
    "sns.histplot(x='LikertResp', hue='Block', data=df_responses, bins=4, discrete=True, ax=axs[1, 1], multiple='dodge', element='poly')\n",
    "axs[1, 1].set_xticks([1, 2, 3, 4], labels=['1', '2', '3', '4'])\n",
    "axs[1, 1].set_xlabel('Response')\n",
    "for t, l in zip(axs[1, 1].legend_.texts, ['A -> V', 'V -> V', 'AV -> V']):\n",
    "    t.set_text(l)\n",
    "axs[1, 1].set_title('How confident are you in your decision?')\n",
    "sns.move_legend(axs[1, 1], \"upper left\", bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844f7291-ebd9-48de-8a72-6beed84f642e",
   "metadata": {},
   "source": [
    "## Participant performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fcb19d-854d-4ba3-ab68-c3a5ee365e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(data=None, type=None):\n",
    "    hit = len(data[(data.Condition == 'true') & (data.Resp == 'g')])\n",
    "    cr = len(data[(data.Condition == 'fake') & (data.Resp == 'h')])\n",
    "    miss = len(data[(data.Condition == 'true') & (data.Resp == 'h')])\n",
    "    fa = len(data[((data.Condition == 'fake') & (data.Resp == 'g'))])\n",
    "\n",
    "    if type == 'sdt':\n",
    "        hit_rate = hit / (hit+miss)\n",
    "        fa_rate = fa / (fa+cr)\n",
    "        d_prime = stats.norm.ppf(hit_rate) - stats.norm.ppf(fa_rate)\n",
    "        res = pd.Series({\n",
    "                            'Hit Rate':hit_rate, \n",
    "                            'False Alarm Rate':fa_rate, \n",
    "                            'd prime':d_prime\n",
    "                        })\n",
    "    elif type == 'accuracy':\n",
    "        res = (hit+cr)/len(data)\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def ttest_between_blocks(data, block1, block2, metric):\n",
    "    res = stats.ttest_rel(\n",
    "        data[data.Block==block1][metric].to_numpy(), \n",
    "        data[data.Block==block2][metric].to_numpy()\n",
    "    )\n",
    "    print(\n",
    "        f't-test between {info.block_map[block1]} & {info.block_map[block2]}: t({res.df})={res.statistic:.2f}, p={res.pvalue:.2f}'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338e36bf-fb43-4489-b0a8-7259d971a3b7",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930e7ebd-05a2-46ac-b04a-5c64d3b9be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc = df_responses.groupby(['Subject', 'Block'], as_index=False).apply(lambda x: pd.Series({'Accuracy': get_stats(x, 'accuracy')}))\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, sharey=True, figsize=(10, 4))\n",
    "plt.tight_layout(w_pad=2)\n",
    "sns.boxplot(y=df_acc.groupby('Subject').Accuracy.mean().to_numpy(), width=0.25, color='k', fill=False, ax=axs[0])\n",
    "sns.stripplot(y=df_acc.groupby('Subject').Accuracy.mean().to_numpy(), alpha=0.3, color='k', ax=axs[0])\n",
    "axs[0].set_ylim(0, 1)\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].axhline(y=0.5, c='k', ls='--', alpha=0.5)\n",
    "axs[0].set_title('Accuracy over all participants')\n",
    "\n",
    "res = stats.ttest_1samp(df_acc.groupby('Subject').Accuracy.mean().to_numpy(), 0.5)\n",
    "print(f't-test for above chance accuracy: t({res.df})={res.statistic:.2f}, p={res.pvalue:.2f}')\n",
    "\n",
    "\n",
    "sns.boxplot(y='Accuracy', x='Block', hue='Block', data=df_acc, fill=False, gap=0.1)\n",
    "sns.stripplot(y='Accuracy', x='Block', hue='Block', data=df_acc, alpha=0.3, legend=False)\n",
    "axs[1].set_ylim(0, 1)\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].set_xlabel('')\n",
    "axs[1].axhline(y=0.5, c='k', ls='--', alpha=0.5)\n",
    "axs[1].set_xticks([0, 1, 2], list(info.block_map.values()))\n",
    "axs[1].set_title('Accuracy over all participants by modality')\n",
    "\n",
    "ttest_between_blocks(df_acc, 'va', 'vv', 'Accuracy')\n",
    "ttest_between_blocks(df_acc, 'va', 'vva', 'Accuracy')\n",
    "ttest_between_blocks(df_acc, 'vv', 'vva', 'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eb0d68-0315-4c6f-a4af-fec56acd8a7d",
   "metadata": {},
   "source": [
    "### SDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea456703-ffa7-4043-be26-c9782638f933",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sdt = df_responses.groupby(['Subject', 'Block'], as_index=False).apply(lambda x: get_stats(x, 'sdt')).melt(\n",
    "            id_vars=['Subject', 'Block'], var_name='Measure').reset_index(drop=True)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(10, 4))\n",
    "plt.tight_layout(w_pad=3)\n",
    "sns.boxplot(y='value', data=df_sdt[df_sdt.Measure=='d prime'].groupby('Subject').mean('value'), fill=False, width=0.2, color='black', ax=axs[0])\n",
    "sns.stripplot(y='value', data=df_sdt[df_sdt.Measure=='d prime'].groupby('Subject').mean('value'), alpha=0.3, dodge=True, legend=False, color='black', ax=axs[0])\n",
    "axs[0].set_xticks([])\n",
    "axs[0].set_xlabel('')\n",
    "axs[0].set_ylabel(\"d'\")\n",
    "axs[0].axhline(y=0, linestyle='--', color='k', alpha=0.5)\n",
    "axs[0].set_title(\"d' over all participants\")\n",
    "\n",
    "sns.boxplot(y='value', x='Measure', hue='Block', data=df_sdt, fill=False, gap=.1, ax=axs[1])\n",
    "sns.stripplot(y='value', x='Measure', hue='Block', data=df_sdt, alpha=0.3, dodge=True, legend=False, ax=axs[1])\n",
    "axs[1].legend_.set_title('Modality')\n",
    "axs[1].legend(frameon=False)\n",
    "for t, l in zip(axs[1].legend_.texts, list(info.block_map.values())):\n",
    "    t.set_text(l)\n",
    "axs[1].set_xlabel('')\n",
    "axs[1].set_ylabel('Value')\n",
    "axs[1].axhline(y=0, linestyle='--', color='k', alpha=0.5)\n",
    "\n",
    "df_sdt = df_sdt[df_sdt.Measure=='d prime'].rename(columns={'value':'d prime'}).drop('Measure', axis=1)\n",
    "res = stats.ttest_1samp(df_sdt.groupby('Subject').mean('d prime').to_numpy().flatten(), 0)\n",
    "print(f't-test for above chance dprime: t({res.df})={res.statistic:.2f}, p={res.pvalue:.2f}')\n",
    "\n",
    "ttest_between_blocks(df_sdt, 'va', 'vv', 'd prime')\n",
    "ttest_between_blocks(df_sdt, 'va', 'vva', 'd prime')\n",
    "ttest_between_blocks(df_sdt, 'vv', 'vva', 'd prime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057fb4a0-d5d8-4543-ae73-9baf73295a37",
   "metadata": {},
   "source": [
    "## Response vs. trial duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5ea5d8-8520-4c80-b6f1-9bac95c4ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(ncols=2, sharex=True, figsize=(10, 4))\n",
    "plt.tight_layout(w_pad=3)\n",
    "sns.lineplot(y='Accuracy', x='Duration', data=df_responses, ax=axs[0])\n",
    "axs[0].set_ylim(0, 1)\n",
    "\n",
    "sns.lineplot(y='LikertResp', x='Duration', data=df_responses, ax=axs[1])\n",
    "axs[1].set_ylim(1, 4)\n",
    "axs[1].set_ylabel('Confidence Rating');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62201b75-f21c-421c-85ee-cd1f664ef42d",
   "metadata": {},
   "source": [
    "## Distribution of dyad accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c001da-7220-4686-a214-1268b209f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dyad_accuracies = df_responses.groupby('DisplayedDyad').apply(lambda x: get_stats(x, 'accuracy')).to_numpy()\n",
    "\n",
    "ax = sns.histplot(x=dyad_accuracies, kde=True)\n",
    "ax.lines[0].set_color('crimson')\n",
    "ax.set_ylabel('Number of Dyads')\n",
    "ax.set_title('Distribution of dyad accuracies')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf454bb-c91d-4106-92c0-7dae50e16ff0",
   "metadata": {},
   "source": [
    "# Computational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb1dd1-8100-478c-9de9-a355caf78385",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials = pd.read_csv('./stim/all_trials_dispDyad.csv')\n",
    "df_trials = df_trials[df_trials.Modality == info.modality].reset_index(drop=True).drop('Unnamed: 0', axis='columns')\n",
    "\n",
    "df_trials['VideoPath'] = df_trials.VideoPath.str.replace('\\\\', '/')\n",
    "df_trials['Condition'] = df_trials.Condition.apply(lambda x: 'true' if x=='TRUE' else 'fake')\n",
    "\n",
    "df_trials = df_trials[~df_trials.VideoPath.isin(['./stim/processed_extracts/fake/8/4_5_va.mov', './stim/processed_extracts/fake/9/1_3_va.mov'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bb9392-d070-4b43-ac58-9bdbc937c4e5",
   "metadata": {},
   "source": [
    "## TRFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbf142b-addb-42c2-9517-da88fc3455b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_signal(signal, length):\n",
    "    signal_resampled = sci_resample(signal, len(np.arange(0, length, 1/info.sr)))\n",
    "    \n",
    "    signal_resampled = gaussian_filter1d(signal_resampled, sigma=2)\n",
    "\n",
    "    standardize = StandardScaler()\n",
    "    signal_resampled = standardize.fit_transform(signal_resampled.reshape(-1, 1))\n",
    "\n",
    "    return signal_resampled.flatten()\n",
    "\n",
    "\n",
    "def get_data(data_type, file, length, au=None):\n",
    "    match data_type:\n",
    "        case 'rms':\n",
    "            audio, audio_sr = librosa.load(file)\n",
    "            rms_win = 0.5\n",
    "            rms_hop = 1/info.sr\n",
    "            rms = librosa.feature.rms(y=audio, frame_length=int(info.sr*rms_win), hop_length=int(info.sr*rms_hop))\n",
    "            data=rms[0]\n",
    "        case 'auditory_nerve':\n",
    "            file = file.replace(os.sep, '/')\n",
    "            df = pd.read_csv(file, usecols=[1])\n",
    "            data = df.to_numpy().flatten()\n",
    "        case 'au':\n",
    "            data = pd.read_csv(file)[au].to_numpy()\n",
    "        case _:\n",
    "            raise ValueError(f\"{data_type} not a valid value for type. Valid values are: ['rms', 'auditory_nerve', 'au']\")\n",
    "    \n",
    "    data_resampled = resample_signal(data, length)\n",
    "\n",
    "    return data_resampled\n",
    "\n",
    "\n",
    "def prepare_input(row):\n",
    "    video_path = row.VideoPath\n",
    "    audio_path = row.AudioPath\n",
    "    disp_dyad = row.DisplayedDyad\n",
    "    duration = row.Duration\n",
    "    condition = row.Condition\n",
    "    au_path = f\"./data/aus_pure/va/{condition}/{disp_dyad}_{video_path.split('/')[-1].replace('.mov', '_aus.csv')}\"\n",
    "    an_path = audio_path.replace('_audio.wav', '.csv').replace('audio', 'audio_carney')\n",
    "\n",
    "    stims = []\n",
    "    resps = []\n",
    "    if os.path.exists(au_path):\n",
    "        stim = get_data(data_type=info.audio_type, file=an_path, length=duration)\n",
    "        for au in info.aus:\n",
    "            stims.append(stim)\n",
    "            resp = get_data(data_type='au', file=au_path, length=duration, au=au)\n",
    "            resps.append(resp)\n",
    "    \n",
    "    return info.aus, stims, resps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31b990a-5ad8-4764-a192-51132027b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials[['AU', 'Stim', 'Resp']] = df_trials.apply(lambda x: prepare_input(x), axis=1, result_type='expand')\n",
    "df_trials = df_trials.explode(column=['AU', 'Stim', 'Resp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04be594-23ae-4f64-90ff-0346925ff883",
   "metadata": {},
   "source": [
    "### Train TRF on true trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab60b80-9f5a-429c-b7a1-cd4cad093114",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for au in info.aus:\n",
    "    stims = df_trials[(df_trials.Condition=='true') & (df_trials.AU==au)].Stim\n",
    "    resps = df_trials[(df_trials.Condition=='true') & (df_trials.AU==au)].Resp\n",
    "\n",
    "    trf = TRF(direction=1)\n",
    "    r_unbiased, best_regularization = nested_crossval(\n",
    "        model=trf, \n",
    "        stimulus=stims, \n",
    "        response=resps, \n",
    "        fs=info.sr, \n",
    "        tmin=info.trf_min_lag, \n",
    "        tmax=info.trf_max_lag, \n",
    "        regularization=info.regularization, \n",
    "        k=5, \n",
    "        verbose=False,\n",
    "        seed=1\n",
    "    )\n",
    "    trf.train(\n",
    "                stimulus=stims, \n",
    "                response=resps, \n",
    "                fs=info.sr, \n",
    "                tmin=info.trf_min_lag, \n",
    "                tmax=info.trf_max_lag, \n",
    "                regularization=best_regularization,\n",
    "                seed=1\n",
    "    )\n",
    "    info.add_trf(au, trf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969ca85a-bd94-4d0c-9420-1aa49b04b564",
   "metadata": {},
   "source": [
    "### Predict responses to all trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40fff8-40de-4448-a2ba-d358f9a08268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_response(row):\n",
    "    prediction, correlation = info.trfs[row.AU].predict(stimulus=row.Stim, response=row.Resp)\n",
    "    prediction = np.array(prediction).flatten()\n",
    "\n",
    "    return prediction, correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed7d317-7af5-4241-9442-e15ec8a2ffa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials[['Prediction', 'Pearsonr']] = df_trials.apply(lambda x: predict_response(x), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dceb86-798e-47ff-a467-146c3340da24",
   "metadata": {},
   "source": [
    "### Prediction accuracy True vs. Fake trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2cb9ce-78f8-434c-9b8d-d052c58ae7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest_true_fake(metric, k):\n",
    "    t = []\n",
    "    p = []\n",
    "    for au in info.aus:\n",
    "        res = stats.ttest_ind(\n",
    "            df_trials[(df_trials.AU==au) & (df_trials.Condition=='true')][metric].to_list(),\n",
    "            df_trials[(df_trials.AU==au) & (df_trials.Condition=='fake')][metric].to_list()\n",
    "        )\n",
    "        t.append(res.statistic)\n",
    "        p.append(res.pvalue)\n",
    "        if res.pvalue < 0.05:\n",
    "            info.add_important_au(k, au, res)\n",
    "\n",
    "    sig = ['*' if p_temp < 0.05 else 'n.s.' for p_temp in p]\n",
    "    sns.barplot(x=np.asarray(info.aus), y=np.array(t), hue=sig, palette={'*': 'g', 'n.s.': 'k'})\n",
    "    plt.xlabel('Action Unit')\n",
    "    plt.ylabel('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95032c37-e13b-496c-99b7-7eb1d0fbef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_true_fake('Pearsonr', 'trf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e7b9bd-c49d-48d9-9f95-c37cc51ab73a",
   "metadata": {},
   "source": [
    "### Plot TRFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559008cb-1ddb-401b-a4b3-e33902db6bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trf(direction, trf, channel=None, feature=None, axes=None, show=True, kind=\"line\"):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        channel (None | int | str): Channel selection. If None, all channels will be used. If an integer, the channel at that index will be used. If 'avg' or 'gfp' , the average or standard deviation across channels will be computed.\n",
    "        feature (None | int | str): Feature selection. If None, all features will be used. If an integer, the feature at that index will be used. If 'avg' , the average across features will be computed.\n",
    "        axes (matplotlib.axes.Axes): Axis to plot to. If None is provided (default) generate a new plot.\n",
    "    \"\"\"\n",
    "    if axes is None:\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    else:\n",
    "        fig, ax = None, axes  # dont create a new figure\n",
    "    weights = trf.weights\n",
    "    # select channel and or feature\n",
    "    if weights.shape[0] == 1:\n",
    "        feature = 0\n",
    "    if weights.shape[-1] == 1:\n",
    "        channel = 0\n",
    "    if channel is None and feature is None:\n",
    "        raise ValueError(\"You must specify a subset of channels or features!\")\n",
    "    if feature is not None:\n",
    "        image_ylabel = \"channel\"\n",
    "        if isinstance(feature, int):\n",
    "            weights = weights[feature, :, :]\n",
    "        elif feature == \"avg\":\n",
    "            weights = weights.mean(axis=0)\n",
    "        else:\n",
    "            raise ValueError('Argument `feature` must be an integer or \"avg\"!')\n",
    "    if channel is not None:\n",
    "        image_ylabel = \"feature\"\n",
    "        if isinstance(channel, int):\n",
    "            weights = weights.T[channel].T\n",
    "        elif channel == \"avg\":\n",
    "            weights = weights.mean(axis=-1)\n",
    "        elif channel == \"gfp\":\n",
    "            weights = weights.std(axis=-1)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'Argument `channel` must be an integer, \"avg\" or \"gfp\"'\n",
    "            )\n",
    "        weights = weights.T  # transpose so first dimension is time\n",
    "    # plot the result\n",
    "    scaler = StandardScaler()\n",
    "    if kind == \"line\":\n",
    "        # ax.plot(\n",
    "        #     trf.times.flatten(), scaler.fit_transform(weights.reshape(-1, 1)), linewidth=2 - 0.01 * weights.shape[-1]\n",
    "        # )\n",
    "        ax.plot(\n",
    "            trf.times.flatten(), scaler.fit_transform(weights.reshape(-1, 1)), linewidth=2, color='k'\n",
    "        )\n",
    "        ax.set(\n",
    "            xlabel=\"Time lag[s]\",\n",
    "            ylabel=\"Amplitude [a.u.]\",\n",
    "            xlim=(trf.times.min(), trf.times.max()),\n",
    "            ylim=(-2.5, 2.5)\n",
    "        )\n",
    "        ax.axhline(y=0, color='k', linestyle='--', alpha=0.25)\n",
    "    if show is True:\n",
    "        plt.show()\n",
    "    if fig is not None:\n",
    "        return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32af8007-0cdb-4e52-9529-adcf9cebdc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplots_adjust(hspace=1, wspace=0.5)\n",
    "for i, (au, trf) in enumerate(info.trfs.items()):\n",
    "    ax = plt.subplot(4, 3, i + 1)\n",
    "    plot_trf(direction=1, trf=trf, axes=ax, show=False) \n",
    "    ax.set_title(au)\n",
    "    ax.get_lines()[0].set_color(\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa158b7-20d5-4487-9887-c46ecf017066",
   "metadata": {},
   "source": [
    "## DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5a9282-8df4-4cae-a30d-6360687d1018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dtw_distance(row):\n",
    "    # define the shape descriptor to use for DTW\n",
    "    slope_descriptor = SlopeDescriptor(slope_window=5)\n",
    "    # DTW of the two time series\n",
    "    shape_dtw_dependent_results = shape_dtw(\n",
    "        x=row.Resp,\n",
    "        y=row.Prediction,\n",
    "        subsequence_width=30, # so this means for the matching that we take about 10 indices into account\n",
    "        shape_descriptor=slope_descriptor\n",
    "    )\n",
    "    dependent_distance = round(shape_dtw_dependent_results.distance, 2)\n",
    "    # normalize distance (squash between 0 and 1)\n",
    "    dependent_distance_normalized = shape_dtw_dependent_results.normalized_distance\n",
    "\n",
    "    return dependent_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7672e7-fa15-408c-9cab-e111aef99521",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trials['DTWDistance'] = df_trials.apply(lambda x: dtw_distance(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9d26e1-f4a6-490d-9bed-969c7f268845",
   "metadata": {},
   "source": [
    "### Distance between True and Fake trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293f7bda-d2b6-4e18-9899-928e1d9b0b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_true_fake('DTWDistance', 'dtw')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e15b404-16bb-4536-9de9-528cc33f0181",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8aa130-348c-4016-a220-0a9f174a856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_data(group):\n",
    "    feature = group.Pearsonr.to_numpy()\n",
    "    target = group.Condition.to_numpy()[0]\n",
    "    trial = group.VideoPath.to_numpy()[0]\n",
    "    \n",
    "    return feature, target, trial\n",
    "\n",
    "\n",
    "def nested_cv(features, targets):\n",
    "\tN_TRIALS = 10\n",
    "\tscores = np.zeros(N_TRIALS)\n",
    "\n",
    "\tsvc = SVC(probability=True)\n",
    "\tparam_grid = [{'C': np.logspace(-5, 3, 9), 'kernel':['linear']}]\n",
    "\n",
    "\tfor i in range(N_TRIALS):\n",
    "\t\tinner_cv = KFold(n_splits=5, shuffle=True, random_state=i)\n",
    "\t\touter_cv = KFold(n_splits=3, shuffle=True, random_state=i)\n",
    "\n",
    "\t\tmodel = GridSearchCV(estimator=svc, param_grid=param_grid, cv=inner_cv)\n",
    "\t\tmodel.fit(features, targets)\n",
    "\n",
    "\t\ttest_score = cross_val_score(model, features, targets, cv=outer_cv)\n",
    "\t\tscores[i] = test_score.mean()\n",
    "\n",
    "\treturn scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ddf83-f9db-4778-a893-6a98f33a1d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_data = []\n",
    "df_trials.groupby('VideoPath').apply(lambda x: svm_data.append(get_training_data(x)))\n",
    "\n",
    "features, targets, ids = map(list, zip(*svm_data))\n",
    "# Standardize features (i.e. - Pearson r values) before training SVM on it\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, targets, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010e76de-4a3f-4e72-952a-0d2282e9ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = nested_cv(scaled_features, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bc0b49-e7f1-4ed3-a2a7-22442c64ff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Unbiased accuracy (using nested cross-validation): µ={np.asarray(scores).mean():.2f}, SD={np.asarray(scores).std():.2f}')\n",
    "res = stats.ttest_1samp(scores, 0.5)\n",
    "print(f't-test for above chance performance: t({res.df})={res.statistic:.2f}, p={res.pvalue:.2f}')\n",
    "\n",
    "sns.boxplot(data=scores, width=0.25, fill=False, color='k')\n",
    "sns.stripplot(data=scores, alpha=0.25, color='k')\n",
    "plt.axhline(y=0.5, color='k', ls='--')\n",
    "plt.ylabel('SVM accuracy')\n",
    "plt.xlabel('')\n",
    "plt.xticks([])\n",
    "plt.ylim(0, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eba713-aead-427e-8ae5-207786c4d45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(probability=True)\n",
    "param_grid = [{'C': np.logspace(-5, 3, 9), 'kernel':['linear']}]\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "model = GridSearchCV(estimator=svc, param_grid=param_grid, cv=cv, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "final_clf = SVC(C=model.best_params_.get('C'), kernel='linear', probability=True)\n",
    "final_clf.fit(X_train, y_train)\n",
    "print(f'SVM accuracy: {final_clf.score(X_test, y_test):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741341f1-a0bd-4acc-aa05-fc2ba3b780f8",
   "metadata": {},
   "source": [
    "### Shapley values on SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10515b91-160a-4d21-8739-dbb87d053a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "\n",
    "model_labels = final_clf.classes_\n",
    "true_label_idx = np.argwhere(model_labels=='true')[0][0]\n",
    "fake_label_idx = np.argwhere(model_labels=='fake')[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6bfa21-5ff3-4302-bd88-78125f2bab41",
   "metadata": {},
   "source": [
    "#### Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2810be98-7a11-4b7e-b4c6-1334d7c3b9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(final_clf.predict_proba, X_train, feature_names=info.aus)\n",
    "shap_values = explainer(scaled_features)\n",
    "shap.plots.beeswarm(shap_values[:, :, true_label_idx], max_display=11, show=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73171395-a540-44e6-8a5d-2cfb16f39213",
   "metadata": {},
   "source": [
    "#### CorrExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074f9506-74db-4031-a1d3-e6a125ff7685",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_empirical = CorrExplainer(final_clf.predict_proba, X_train, sampling=\"empirical\", feature_names=info.aus)\n",
    "shap_empirical = ex_empirical(scaled_features)\n",
    "shap.plots.beeswarm(shap_empirical[:, :, true_label_idx], show=False, max_display=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba3e1a-90d5-4820-98ea-e06b44fccb09",
   "metadata": {},
   "source": [
    "# Behavioral x Computational"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb494d4-3619-49f7-91f9-b53388ceb8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dfs(row):\n",
    "    trial = df_trials[df_trials.VideoPath==row.VideoPath]\n",
    "    aus = trial.AU.to_numpy()\n",
    "    rs = trial.Pearsonr.to_numpy()\n",
    "\n",
    "    return aus, rs\n",
    "            \n",
    "\n",
    "df = df_responses[(df_responses.Block == info.modality) & (~df_responses.VideoPath.isin(['./stim/processed_extracts/fake/8/4_5_va.mov', './stim/processed_extracts/fake/9/1_3_va.mov']))]\n",
    "df[['AU', 'Pearsonr']] = df.apply(lambda x: combine_dfs(x), axis=1, result_type='expand')\n",
    "df = df.explode(column=['AU', 'Pearsonr']).reset_index(drop=True)\n",
    "df = df.astype({'Resp': 'category', 'Pearsonr': float})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83fac07-714b-432b-bd52-60b1004dcf34",
   "metadata": {},
   "source": [
    "## LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0660b2-d10c-4ddc-a087-23f77f7db05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lm = df.groupby(['VideoPath', 'AU'], as_index=False).apply(\n",
    "    lambda x: pd.Series({\n",
    "        'Pearsonr': x.Pearsonr.mean(),\n",
    "        'Genuineness': Counter(x.Resp)['g']/len(x)\n",
    "    }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829e0f47-b7aa-4a87-9982-6a49491ba984",
   "metadata": {},
   "outputs": [],
   "source": [
    "for au in info.aus:\n",
    "    model = Lm(\"Genuineness ~ Pearsonr\", data=df_lm[df_lm.AU==au])\n",
    "    model.fit(summarize=False)\n",
    "    if model.coefs.loc['Pearsonr']['P-val'] < 0.05:\n",
    "        print('**********************************************************************')\n",
    "        print(au)\n",
    "        print(model.fit())\n",
    "        info.add_important_au('lm', au, model.fit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68217ef0-492e-4b8e-b47f-b3bc4c8721b4",
   "metadata": {},
   "source": [
    "## GLM (logit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256b227c-589b-46b9-8987-1722a41397e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for au in info.aus:\n",
    "    model = Lmer(\"Resp ~ Pearsonr + (1|Subject)\", family='binomial', data=df[df.AU==au])\n",
    "    model.fit(summarize=False)\n",
    "    if model.coefs.loc['Pearsonr']['P-val'] < 0.05:\n",
    "        print('**********************************************************************')\n",
    "        print(au)\n",
    "        print(model.fit)\n",
    "        info.add_important_au('glm', au, model.fit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1c3b98-4d03-424e-97c9-2ea75b9fab4a",
   "metadata": {},
   "source": [
    "## TRF fit vs. SDT category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b662fd-92c7-43ae-a11f-cca222ed3771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mode_response(data):\n",
    "    mode = data.Resp.mode()\n",
    "    if len(mode) != 1:\n",
    "        confidence = data.groupby('Resp')['LikertResp'].mean()\n",
    "        \n",
    "        confidence_in_true = confidence['g']\n",
    "        confidence_in_fake = confidence['h']\n",
    "        if confidence_in_true > confidence_in_fake:\n",
    "            return 'g'\n",
    "        elif confidence_in_true < confidence_in_fake:\n",
    "             return 'h'\n",
    "        else:\n",
    "            # arbitrary decision (doesn't make a huge amount of difference if 'h' \n",
    "            # or a random choice between 'g' and 'h')\n",
    "            return 'g'\n",
    "    else:\n",
    "        return mode.values[0]\n",
    "\n",
    "\n",
    "def sdt_cat(pair):\n",
    "    match pair:\n",
    "        case ('true', 'g'):\n",
    "            return 'hit'\n",
    "        case ('true', 'h'):\n",
    "            return 'miss'\n",
    "        case ('fake', 'g'):\n",
    "            return 'fa'\n",
    "        case ('fake', 'h'):\n",
    "            return 'cr'\n",
    "\n",
    "\n",
    "df_final = df.groupby(['VideoPath', 'AU'], as_index=False).apply(\n",
    "    lambda x: pd.Series({\n",
    "        'Condition': x.Condition.iloc[0],\n",
    "        'ModeResp': mode_response(x),\n",
    "        'Pearsonr': x.Pearsonr.mean()\n",
    "    }))\n",
    "df_final['SDT'] = df_final.apply(lambda x: sdt_cat((x.Condition, x.ModeResp)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31941fa2-951a-40c5-a139-1315f79637e3",
   "metadata": {},
   "source": [
    "### Participants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bd2bfc-23f9-48f1-a631-11b39a9bc534",
   "metadata": {},
   "source": [
    "#### AU25 vs. AU43 for Hit, Miss, CR & FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657678ea-d568-47eb-98e4-4eaeed667524",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "                data=df_final[(df_final.AU=='AU25') | (df_final.AU=='AU43')],\n",
    "                x='SDT',\n",
    "                y='Pearsonr',\n",
    "                hue='AU',\n",
    "                order=['hit', 'miss', 'cr', 'fa'],\n",
    "                fill=False,\n",
    "                gap=0.15\n",
    "            )\n",
    "plt.axhline(y=0, color='k', linestyle='--', linewidth=0.75)\n",
    "plt.ylabel('TRF fits')\n",
    "plt.xlabel('')\n",
    "plt.ylim(-0.15, 0.2);\n",
    "\n",
    "\n",
    "for cat in df_final.SDT.unique():\n",
    "    temp = df_final[df_final.SDT==cat]\n",
    "    temp_aus = temp[(temp.AU=='AU25') | (temp.AU=='AU43')]\n",
    "\n",
    "    res = stats.ttest_rel(\n",
    "        temp_aus[temp_aus.AU=='AU25'].Pearsonr.to_numpy(), \n",
    "        temp_aus[temp_aus.AU=='AU43'].Pearsonr.to_numpy()\n",
    "    )\n",
    "    print(f't-test between AU25 & AU43 for {cat}: t({res.df})={res.statistic:.2f}, p={res.pvalue:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b59ad-1ae9-4501-86a8-b93d37e9e72e",
   "metadata": {},
   "source": [
    "#### AU25 vs. AU43 for True & Fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df516073-de94-4839-8e0a-498abf3c39e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "                data=df_final[(df_final.AU=='AU25') | (df_final.AU=='AU43')],\n",
    "                x='Condition',\n",
    "                y='Pearsonr',\n",
    "                hue='AU',\n",
    "                fill=False,\n",
    "                gap=0.15\n",
    "            )\n",
    "plt.axhline(y=0, color='k', linestyle='--', linewidth=0.75)\n",
    "plt.ylabel('TRF fits')\n",
    "plt.xlabel('')\n",
    "plt.ylim(-0.15, 0.2);\n",
    "\n",
    "for cond in df_final.Condition.unique():\n",
    "    temp = df_final[df_final.Condition==cond]\n",
    "    temp_aus = temp[(temp.AU=='AU25') | (temp.AU=='AU43')]\n",
    "\n",
    "    res = stats.ttest_rel(\n",
    "        temp[temp.AU=='AU25'].Pearsonr.to_numpy(), \n",
    "        temp[temp.AU=='AU43'].Pearsonr.to_numpy()\n",
    "    )\n",
    "    print(f't-test between AU25 & AU43 for {cond}: t({res.df})={res.statistic:.2f}, p={res.pvalue:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06f754d-e397-4729-844f-b27669bb2c1b",
   "metadata": {},
   "source": [
    "#### Eyes vs. Mouth (combined AUs) for Hit, Miss, CR & FA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c2fa49-b1e1-426b-a952-e246b6a744d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.AU.isin(['AU12', 'AU15', 'AU17', 'AU25', 'AU43'])]\n",
    "df['region'] = df.apply(lambda x: 'eyes' if x.AU=='AU43' else 'mouth', axis=1)\n",
    "\n",
    "df_final = df.groupby(['VideoPath', 'region'], as_index=False).apply(\n",
    "    lambda x: pd.Series({\n",
    "        'Condition': x.Condition.iloc[0],\n",
    "        'ModeResp': mode_response(x),\n",
    "        'Pearsonr': x.Pearsonr.mean()\n",
    "    }))\n",
    "df_final['SDT'] = df_final.apply(lambda x: sdt_cat((x.Condition, x.ModeResp)), axis=1)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a37e4d6-a751-4e5c-ae77-aaa2ea9da1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(\n",
    "                data=df_final,\n",
    "                x='SDT',\n",
    "                y='Pearsonr',\n",
    "                hue='region',\n",
    "                order=['hit', 'miss', 'cr', 'fa'],\n",
    "                hue_order=['mouth', 'eyes'],\n",
    "                fill=False,\n",
    "                gap=0.15\n",
    "            )\n",
    "plt.axhline(y=0, color='k', linestyle='--', linewidth=0.75)\n",
    "plt.ylabel('TRF fits')\n",
    "plt.xlabel('')\n",
    "plt.ylim(-0.15, 0.2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb37dc7-57c1-4fa8-9928-ecbde4ff5bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('main_results.pkl', 'wb') as f:\n",
    "#     pickle.dump(info, f)\n",
    "\n",
    "# with open('main_results.pkl', 'rb') as f:\n",
    "#     test = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0839cc-91c3-4733-81cd-37c4760f0d91",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7803084-615c-46a2-bf17-029c6e956b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.barplot(\n",
    "#                 data=df_last[(df_last['AU']=='AU25') | (df_last['AU']=='AU43')],\n",
    "#                 x='SVM_SDT',\n",
    "#                 y='Pearsonr',\n",
    "#                 hue='AU',\n",
    "#                 order=['hit', 'miss', 'cr', 'fa'],\n",
    "#                 fill=False,\n",
    "#                 gap=0.15\n",
    "#             )\n",
    "# plt.axhline(y=0, color='k', linestyle='--', linewidth=0.75)\n",
    "# plt.ylabel('TRF fits')\n",
    "# plt.xlabel('');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e997ec-07be-477a-a040-1913827d2b91",
   "metadata": {},
   "source": [
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781e5cfc-56a8-44e6-8e17-3e025d1eb068",
   "metadata": {},
   "source": [
    "- Focusing on eyes appears to be a sub-optimal strategy. Changing focus to the mouth might lead to fewer false alarms (and perhaps also fewer misses).\n",
    "\n",
    "============================================================================================================================================================\n",
    "\n",
    "- AU25 might seem like a weird AU to be important in judging genuineness, but it is important to note that it most often co-occurs with AU12 (smile).\n",
    "  - Co-occurring AUs:\n",
    "      - AU17: 15\n",
    "      - AU25: 12\n",
    "\n",
    "============================================================================================================================================================\n",
    "\n",
    "- The reliability of the mouth region compared to the eyes in judging genuineness of interactions can be explained by the fact that mouth movements are more discrete and occur in response to specific events in the Speaker's speech. Blinks, on the other hand, include physiological 'noise' in addition to socially relevant cues. Moreover, cues like smiles are higher-level concepts representing social percepts concretely while the role of blinks and gaze direction is more implicit and low-level such that many people are unaware of the influence the eyes have on social interactions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
