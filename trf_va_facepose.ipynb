{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from feat import Detector\n",
    "import librosa\n",
    "from scipy.signal import resample as sci_resample\n",
    "from mtrf.model import TRF\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rms_envelope(audio_file, reqd_sr):\n",
    "    stim, sr = librosa.load(audio_file)\n",
    "\n",
    "    # Compute RMS \n",
    "    rms_win = 0.01 # 10ms\n",
    "    rms_hop = 1/reqd_sr # hop by eeg sampling rate\n",
    "    rms = librosa.feature.rms(y=stim, frame_length=int(sr*rms_win), hop_length=int(sr*rms_hop))\n",
    "    rms_sr = 1/rms_hop # the rms time series is sampled with period rms_hop\n",
    "    rms=rms[0]\n",
    "\n",
    "    return rms\n",
    "\n",
    "\n",
    "def resample_signal(signal, duration, reqd_sr, num_samples, pad_before):\n",
    "    signal_resampled = sci_resample(signal, len(np.arange(0, duration, 1/reqd_sr)))\n",
    "        \n",
    "    pad_after = num_samples - (len(signal_resampled)+pad_before)\n",
    "    signal_padded = np.pad(signal_resampled, pad_width=(pad_before,pad_after))\n",
    "\n",
    "    return signal_padded\n",
    "\n",
    "\n",
    "def analyse_videos( input_file, \n",
    "                    target_file, \n",
    "                    skip_frames=10, \n",
    "                    # batch_size=900, \n",
    "                    num_workers=16, \n",
    "                    pin_memory=False, \n",
    "                    n_jobs = 12,\n",
    "                    face_model = \"retinaface\",\n",
    "                    landmark_model = \"mobilefacenet\",\n",
    "                    au_model = 'xgb',\n",
    "                    emotion_model = \"resmasknet\",\n",
    "                    facepose_model = \"img2pose\",\n",
    "                    device = \"cuda\"):\n",
    "    #New detector\n",
    "    detector = Detector(\n",
    "        face_model = face_model,\n",
    "        landmark_model = landmark_model,\n",
    "        au_model = au_model,\n",
    "        emotion_model = emotion_model,\n",
    "        facepose_model = facepose_model,\n",
    "        device = device\n",
    "    )\n",
    "\n",
    "    video_prediction = detector.detect_video(input_file\n",
    "                                            , skip_frames = skip_frames\n",
    "                                            # , batch_size = batch_size\n",
    "                                            , num_workers = num_workers\n",
    "                                            , pin_memory = pin_memory\n",
    "                                            , n_jobs = n_jobs)\n",
    "\n",
    "    video_prediction.to_csv(target_file)\n",
    "\n",
    "\n",
    "def get_aus(df, condition):\n",
    "    counter = 0\n",
    "    for i in range(len(df)):\n",
    "        filepath = df.iloc[i]['VideoPath']\n",
    "        disp_dyad = df.iloc[i]['DisplayedDyad']\n",
    "        aus_filepath = f'./data/aus_pure/{condition}/{disp_dyad}_{filepath.split(os.sep)[-1][:-4]}_aus.csv'\n",
    "        print(f'{counter}. ', filepath)\n",
    "        analyse_videos(filepath, aus_filepath)\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./stim/all_trials_dispDyad.csv')\n",
    "\n",
    "df_va = df[df['Modality'] == 'va']\n",
    "df_va_trues = df_va[df_va['Condition'] == 'TRUE']\n",
    "df_va_fakes = df_va[df_va['Condition'] != 'TRUE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format training data for TRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 30\n",
    "min_time_lag = -1                       # in seconds\n",
    "max_time_lag = 26                        # in seconds\n",
    "pad_before = np.abs(sr*min_time_lag)\n",
    "num_samples = (sr*max_time_lag)+(pad_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_all = []\n",
    "nods_all = []\n",
    "\n",
    "for i in range(len(df_va_trues)):\n",
    "    filepath = df_va_trues.iloc[i]['VideoPath']\n",
    "    disp_dyad = df_va_trues.iloc[i]['DisplayedDyad']\n",
    "    duration = df_va_trues.iloc[i]['Duration']\n",
    "    aus_filepath = f'./data/aus_pure/true/{disp_dyad}_{filepath.split(os.sep)[-1][:-4]}_aus.csv'\n",
    "\n",
    "    rms = get_rms_envelope(df_va_trues.iloc[i]['AudioPath'], sr)\n",
    "    rms = resample_signal(rms, duration, sr, num_samples, pad_before)\n",
    "\n",
    "    df = pd.read_csv(aus_filepath)\n",
    "    nods = df['Pitch'].to_numpy()\n",
    "    nods = resample_signal(nods, duration, sr, num_samples, pad_before)\n",
    "\n",
    "    rms_all.append(rms)\n",
    "    nods_all.append(nods)\n",
    "\n",
    "\n",
    "nods_all = np.asarray(nods_all)\n",
    "nods_all_reshaped = []\n",
    "for nod in nods_all:\n",
    "    nods_all_reshaped.append(np.reshape(nod, (-1, 1)))\n",
    "\n",
    "rms_all = np.asarray(rms_all)\n",
    "rms_all_reshaped = []\n",
    "for el in rms_all:\n",
    "    rms_all_reshaped.append(np.reshape(el, (-1, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train TRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trf = TRF(direction=1)\n",
    "# regularization = np.logspace(-1, 6, 20)\n",
    "# [correlation, error] = trf.train(rms_all_reshaped, smiles_all_reshaped, 30, tmin=-1, tmax=26, k=-1, regularization=regularization)\n",
    "trf.train(rms_all_reshaped, nods_all_reshaped, sr, tmin=min_time_lag, tmax=max_time_lag, regularization=1)\n",
    "\n",
    "# fig, ax1 = plt.subplots()\n",
    "# ax2 = ax1.twinx()\n",
    "# ax1.semilogx(regularization, correlation, color='c')\n",
    "# ax2.semilogx(regularization, error, color='m')\n",
    "# ax1.set(xlabel='Regularization value', ylabel='Correlation coefficient')\n",
    "# ax2.set(ylabel='Mean squared error')\n",
    "# ax1.axvline(regularization[np.argmin(error)], linestyle='--', color='k')\n",
    "# plt.show()\n",
    "\n",
    "trf.plot(channel='avg', kind='line');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyad_col = []\n",
    "stim_col = []\n",
    "time_col = []\n",
    "actual_col = []\n",
    "pred_col = []\n",
    "corr_col = []\n",
    "error_col = []\n",
    "\n",
    "for j in range(len(df_va_fakes)):\n",
    "    input_rms = get_rms_envelope(df_va_fakes.iloc[j]['AudioPath'], sr)\n",
    "    input_rms = resample_signal(input_rms, duration, sr, num_samples, pad_before)\n",
    "    input_rms = np.asarray(input_rms)\n",
    "    input_rms_reshaped = np.reshape(input_rms, (-1, 1))\n",
    "\n",
    "    # Actual\n",
    "    filepath = df_va_fakes.iloc[j]['VideoPath']\n",
    "    disp_dyad = df_va_fakes.iloc[j]['DisplayedDyad']\n",
    "    speaker_extract = df_va_fakes.iloc[j]['SpeakerExtract']\n",
    "    listener_extract = df_va_fakes.iloc[j]['ListenerExtract']\n",
    "    duration = df_va_fakes.iloc[j]['Duration']\n",
    "    aus_filepath = f'./data/aus_pure/fake/{disp_dyad}_{filepath.split(os.sep)[-1][:-4]}_aus.csv'\n",
    "\n",
    "    if os.path.exists(aus_filepath):\n",
    "        df = pd.read_csv(aus_filepath)\n",
    "        actual_nod = df['Pitch'].to_numpy()\n",
    "        actual_nod = resample_signal(actual_nod, duration, sr, num_samples, pad_before)\n",
    "        actual_nod = np.asarray(actual_nod)\n",
    "        nod_reshaped = np.reshape(actual_nod, (-1, 1))\n",
    "        \n",
    "        dyad_col.append(np.repeat(disp_dyad, num_samples))\n",
    "        stim = str(disp_dyad)+'_'+filepath.split(os.sep)[-1][:-6]\n",
    "        stim_col.append(np.repeat(stim, num_samples))\n",
    "        time_col.append(np.arange(min_time_lag, max_time_lag, 1/sr))\n",
    "        actual_col.append(actual_nod)\n",
    "        \n",
    "        # Predicted\n",
    "        [prediction, correlation, error] = trf.predict(input_rms_reshaped, nod_reshaped, average=True)\n",
    "        pred_col.append(np.asanyarray(prediction).flatten())\n",
    "        corr_col.append(np.repeat(correlation, num_samples))\n",
    "        error_col.append(np.repeat(error, num_samples))\n",
    "\n",
    "        # sns.lineplot(y=np.asanyarray(smiles).flatten(), x=np.arange(min_time_lag, max_time_lag, 1/sr))\n",
    "        # sns.lineplot(y=np.asanyarray(prediction).flatten(), x=np.arange(min_time_lag, max_time_lag, 1/sr))\n",
    "        # plt.ylabel('AU12')\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trf = pd.DataFrame({\n",
    "                        'Dyad': np.asanyarray(dyad_col).flatten(),\n",
    "                        'Stim': np.asanyarray(stim_col).flatten(),\n",
    "                        'Time': np.asanyarray(time_col).flatten(),\n",
    "                        'Actual': np.asanyarray(actual_col).flatten(), \n",
    "                        'Predicted': np.asanyarray(pred_col).flatten(),\n",
    "                        'Correlation': np.asanyarray(corr_col).flatten(),\n",
    "                        'Error': np.asanyarray(error_col).flatten()\n",
    "                    })\n",
    "df_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=df_trf, y='Actual', x='Time', errorbar='ci')\n",
    "sns.lineplot(data=df_trf, y='Predicted', x='Time', errorbar='ci')\n",
    "plt.ylabel('Head Pitch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trf_pred = df_trf.groupby(['Dyad']).agg({'Correlation': 'mean', 'Error': 'mean'})\n",
    "df_trf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_vals = np.arctanh(df_trf_pred['Correlation'].to_numpy())\n",
    "avg_z = np.mean(z_vals)\n",
    "r = np.tanh(avg_z)\n",
    "print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speedDating",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
